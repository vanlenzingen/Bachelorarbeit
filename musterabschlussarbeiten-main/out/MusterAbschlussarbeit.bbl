% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{hui_alphago_2018}{misc}{}
      \name{author}{1}{}{%
        {{hash=6cfb5d2608616bce21708f853f01106e}{%
           family={Hui},
           familyi={H\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{6cfb5d2608616bce21708f853f01106e}
      \strng{fullhash}{6cfb5d2608616bce21708f853f01106e}
      \strng{bibnamehash}{6cfb5d2608616bce21708f853f01106e}
      \strng{authorbibnamehash}{6cfb5d2608616bce21708f853f01106e}
      \strng{authornamehash}{6cfb5d2608616bce21708f853f01106e}
      \strng{authorfullhash}{6cfb5d2608616bce21708f853f01106e}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{How does reinforcement learning join force with deep learning to beat the Go master? Since it sounds implausible, the technology behind it…}
      \field{journaltitle}{Medium}
      \field{month}{5}
      \field{shorttitle}{{AlphaGo}}
      \field{title}{{AlphaGo}: {How} it works technically?}
      \field{urlday}{7}
      \field{urlmonth}{2}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tony/Zotero/storage/HBW88KF8/alphago-how-it-works-technically-26ddcc085319.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://jonathan-hui.medium.com/alphago-how-it-works-technically-26ddcc085319
      \endverb
      \verb{url}
      \verb https://jonathan-hui.medium.com/alphago-how-it-works-technically-26ddcc085319
      \endverb
      \keyw{AlphaGo}
    \endentry
    \entry{noauthor_alphago_2020}{misc}{}
      \list{language}{1}{%
        {en}%
      }
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labeltitlesource}{title}
      \field{abstract}{Novel AI system mastered the ancient game of Go, defeated a Go world champion, and inspired a new era of AI.}
      \field{journaltitle}{Google DeepMind}
      \field{month}{12}
      \field{title}{{AlphaGo}}
      \field{urlday}{4}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tony/Zotero/storage/77AGAZ5X/alphago.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://deepmind.google/technologies/alphago/
      \endverb
      \verb{url}
      \verb https://deepmind.google/technologies/alphago/
      \endverb
    \endentry
    \entry{lorenz_reinforcement_2020}{book}{}
      \name{author}{1}{}{%
        {{hash=8a862104cedf12a3c82f476a82c0f5f5}{%
           family={Lorenz},
           familyi={L\bibinitperiod},
           given={Uwe},
           giveni={U\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {de}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{8a862104cedf12a3c82f476a82c0f5f5}
      \strng{fullhash}{8a862104cedf12a3c82f476a82c0f5f5}
      \strng{bibnamehash}{8a862104cedf12a3c82f476a82c0f5f5}
      \strng{authorbibnamehash}{8a862104cedf12a3c82f476a82c0f5f5}
      \strng{authornamehash}{8a862104cedf12a3c82f476a82c0f5f5}
      \strng{authorfullhash}{8a862104cedf12a3c82f476a82c0f5f5}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-3-662-61650-5 978-3-662-61651-2}
      \field{shorttitle}{Reinforcement {Learning}}
      \field{title}{Reinforcement {Learning}: {Aktuelle} {Ansätze} verstehen - mit {Beispielen} in {Java} und {Greenfoot}}
      \field{urlday}{8}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2020}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-662-61651-2
      \endverb
      \verb{file}
      \verb Lorenz - 2020 - Reinforcement Learning Aktuelle Ansätze verstehen.pdf:/home/tony/Zotero/storage/IGE2YC7S/Lorenz - 2020 - Reinforcement Learning Aktuelle Ansätze verstehen.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-662-61651-2
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-662-61651-2
      \endverb
    \endentry
    \entry{ertel_grundkurs_2021}{book}{}
      \name{author}{1}{}{%
        {{hash=0ad7b7b50f220390cbf1c36575c6a49a}{%
           family={Ertel},
           familyi={E\bibinitperiod},
           given={Wolfgang},
           giveni={W\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {de}%
      }
      \list{location}{1}{%
        {Wiesbaden}%
      }
      \list{publisher}{1}{%
        {Springer Fachmedien Wiesbaden}%
      }
      \strng{namehash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \strng{fullhash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \strng{bibnamehash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \strng{authorbibnamehash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \strng{authornamehash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \strng{authorfullhash}{0ad7b7b50f220390cbf1c36575c6a49a}
      \field{sortinit}{3}
      \field{sortinithash}{ad6fe7482ffbd7b9f99c9e8b5dccd3d7}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-3-658-32074-4 978-3-658-32075-1}
      \field{series}{Computational {Intelligence}}
      \field{shorttitle}{Grundkurs {Künstliche} {Intelligenz}}
      \field{title}{Grundkurs {Künstliche} {Intelligenz}: {Eine} praxisorientierte {Einführung}}
      \field{urlday}{9}
      \field{urlmonth}{2}
      \field{urlyear}{2024}
      \field{year}{2021}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-658-32075-1
      \endverb
      \verb{file}
      \verb Ertel - 2021 - Grundkurs Künstliche Intelligenz Eine praxisorien.pdf:/home/tony/Zotero/storage/5DDBEV4I/Ertel - 2021 - Grundkurs Künstliche Intelligenz Eine praxisorien.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-658-32075-1
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-658-32075-1
      \endverb
    \endentry
    \entry{noauthor_kunstliche_nodate}{misc}{}
      \list{language}{1}{%
        {de-CH}%
      }
      \field{sortinit}{4}
      \field{sortinithash}{9381316451d1b9788675a07e972a12a7}
      \field{labeltitlesource}{title}
      \field{abstract}{Informatik Gymnasium Kirchenfeld}
      \field{title}{Künstliche {Neuronale} {Netze} {|} {EF} {Informatik} 2023}
      \field{urlday}{6}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tony/Zotero/storage/WW8E8BJX/08-knn.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://informatik.mygymer.ch/ef2023/07-ki/08-knn.html#kunstliches-neuron
      \endverb
      \verb{url}
      \verb https://informatik.mygymer.ch/ef2023/07-ki/08-knn.html#kunstliches-neuron
      \endverb
    \endentry
    \entry{zhang_study_2018}{misc}{}
      \name{author}{4}{}{%
        {{hash=02582b039d752b000c75f8d7d38a36f4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Chiyuan},
           giveni={C\bibinitperiod}}}%
        {{hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod}}}%
        {{hash=ce2c8d8bf1e96e9845a930fb6264204f}{%
           family={Munos},
           familyi={M\bibinitperiod},
           given={Remi},
           giveni={R\bibinitperiod}}}%
        {{hash=02404a92b0be3f52ec5ac08e41c13445}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Samy},
           giveni={S\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{aefa5e3824e928a3f030ca71f5599336}
      \strng{fullhash}{be58f81afa9d10937fdd47a3a1654bf0}
      \strng{bibnamehash}{aefa5e3824e928a3f030ca71f5599336}
      \strng{authorbibnamehash}{aefa5e3824e928a3f030ca71f5599336}
      \strng{authornamehash}{aefa5e3824e928a3f030ca71f5599336}
      \strng{authorfullhash}{be58f81afa9d10937fdd47a3a1654bf0}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent years have witnessed significant progresses in deep Reinforcement Learning (RL). Empowered with large scale neural networks, carefully designed architectures, novel training algorithms and massively parallel computing devices, researchers are able to attack many challenging RL problems. However, in machine learning, more training power comes with a potential risk of more overfitting. As deep RL techniques are being applied to critical problems such as healthcare and finance, it is important to understand the generalization behaviors of the trained agents. In this paper, we conduct a systematic study of standard RL agents and find that they could overfit in various ways. Moreover, overfitting could happen “robustly”: commonly used techniques in RL that add stochasticity do not necessarily prevent or detect overfitting. In particular, the same agents and learning algorithms could have drastically different test performance, even when all of them achieve optimal rewards during training. The observations call for more principled and careful evaluation protocols in RL. We conclude with a general discussion on overfitting in RL and a study of the generalization behaviors from the perspective of inductive bias.}
      \field{month}{4}
      \field{note}{arXiv:1804.06893 [cs, stat]}
      \field{title}{A {Study} on {Overfitting} in {Deep} {Reinforcement} {Learning}}
      \field{urlday}{18}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2018}
      \field{urldateera}{ce}
      \verb{file}
      \verb Zhang et al. - 2018 - A Study on Overfitting in Deep Reinforcement Learn.pdf:/home/tony/Zotero/storage/GZJTFDLH/Zhang et al. - 2018 - A Study on Overfitting in Deep Reinforcement Learn.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1804.06893
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1804.06893
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning}
    \endentry
    \entry{pan_effects_2022}{misc}{}
      \name{author}{3}{}{%
        {{hash=235e79000a1b533780d88dfb7b9ea6df}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=dd86a3873bf4d9d6b4c5eebc3cee3099}{%
           family={Bhatia},
           familyi={B\bibinitperiod},
           given={Kush},
           giveni={K\bibinitperiod}}}%
        {{hash=fe7a7e80c1857d185d3ab01f15fe584d}{%
           family={Steinhardt},
           familyi={S\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{a2413c137a86f8e1dfee00e10dc6e332}
      \strng{fullhash}{a2413c137a86f8e1dfee00e10dc6e332}
      \strng{bibnamehash}{a2413c137a86f8e1dfee00e10dc6e332}
      \strng{authorbibnamehash}{a2413c137a86f8e1dfee00e10dc6e332}
      \strng{authornamehash}{a2413c137a86f8e1dfee00e10dc6e332}
      \strng{authorfullhash}{a2413c137a86f8e1dfee00e10dc6e332}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Reward hacking—where RL agents exploit gaps in misspeciﬁed reward functions—has been widely observed, but not yet systematically studied. To understand how reward hacking arises, we construct four RL environments with misspeciﬁed rewards. We investigate reward hacking as a function of agent capabilities: model capacity, action space resolution, observation space noise, and training time. More capable agents often exploit reward misspeciﬁcations, achieving higher proxy reward and lower true reward than less capable agents. Moreover, we ﬁnd instances of phase transitions: capability thresholds at which the agent’s behavior qualitatively shifts, leading to a sharp decrease in the true reward. Such phase transitions pose challenges to monitoring the safety of ML systems. To address this, we propose an anomaly detection task for aberrant policies and offer several baseline detectors.}
      \field{month}{2}
      \field{note}{arXiv:2201.03544 [cs, stat]}
      \field{shorttitle}{The {Effects} of {Reward} {Misspecification}}
      \field{title}{The {Effects} of {Reward} {Misspecification}: {Mapping} and {Mitigating} {Misaligned} {Models}}
      \field{urlday}{18}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Pan et al. - 2022 - The Effects of Reward Misspecification Mapping an.pdf:/home/tony/Zotero/storage/WUXVYDS6/Pan et al. - 2022 - The Effects of Reward Misspecification Mapping an.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2201.03544
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2201.03544
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence}
    \endentry
    \entry{hare_dealing_2019}{misc}{}
      \name{author}{1}{}{%
        {{hash=83e24fcc6242caf96afa6491eea044d9}{%
           family={Hare},
           familyi={H\bibinitperiod},
           given={Joshua},
           giveni={J\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{publisher}{1}{%
        {arXiv}%
      }
      \strng{namehash}{83e24fcc6242caf96afa6491eea044d9}
      \strng{fullhash}{83e24fcc6242caf96afa6491eea044d9}
      \strng{bibnamehash}{83e24fcc6242caf96afa6491eea044d9}
      \strng{authorbibnamehash}{83e24fcc6242caf96afa6491eea044d9}
      \strng{authornamehash}{83e24fcc6242caf96afa6491eea044d9}
      \strng{authorfullhash}{83e24fcc6242caf96afa6491eea044d9}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Successfully navigating a complex environment to obtain a desired outcome is a difficult task, that up to recently was believed to be capable only by humans. This perception has been broken down over time, especially with the introduction of deep reinforcement learning, which has greatly increased the difficulty of tasks that can be automated. However, for traditional reinforcement learning agents this requires an environment to be able to provide frequent extrinsic rewards, which are not known or accessible for many real-world environments. This project aims to explore and contrast existing reinforcement learning solutions that circumnavigate the difficulties of an environment that provide sparse rewards. Different reinforcement solutions will be implemented over a several video game environments with varying difficulty and varying frequency of rewards, as to properly investigate the applicability of these solutions. This project introduces a novel reinforcement learning solution by combining aspects of two existing state of the art sparse reward solutions, curiosity driven exploration and unsupervised auxiliary tasks.}
      \field{month}{11}
      \field{note}{arXiv:1910.09281 [cs, stat]}
      \field{title}{Dealing with {Sparse} {Rewards} in {Reinforcement} {Learning}}
      \field{urlday}{18}
      \field{urlmonth}{3}
      \field{urlyear}{2024}
      \field{year}{2019}
      \field{urldateera}{ce}
      \verb{file}
      \verb Hare - 2019 - Dealing with Sparse Rewards in Reinforcement Learn.pdf:/home/tony/Zotero/storage/EJYWRWXA/Hare - 2019 - Dealing with Sparse Rewards in Reinforcement Learn.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1910.09281
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1910.09281
      \endverb
      \keyw{Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Artificial Intelligence}
    \endentry
    \entry{zai_einstieg_2020}{book}{}
      \name{author}{2}{}{%
        {{hash=76ef884b8027b8e3fdc12924571ff47d}{%
           family={Zai},
           familyi={Z\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=68d993801b92db44cfb896bf4503c03f}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Brandon},
           giveni={B\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {München}%
      }
      \list{publisher}{1}{%
        {Hanser}%
      }
      \strng{namehash}{108e0694257ede1a3b96e213513bb90b}
      \strng{fullhash}{108e0694257ede1a3b96e213513bb90b}
      \strng{bibnamehash}{108e0694257ede1a3b96e213513bb90b}
      \strng{authorbibnamehash}{108e0694257ede1a3b96e213513bb90b}
      \strng{authornamehash}{108e0694257ede1a3b96e213513bb90b}
      \strng{authorfullhash}{108e0694257ede1a3b96e213513bb90b}
      \field{sortinit}{9}
      \field{sortinithash}{0a5ebc79d83c96b6579069544c73c7d4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-3-446-45900-7}
      \field{shorttitle}{Einstieg in {Deep} {Reinforcement} {Learning}}
      \field{title}{Einstieg in {Deep} {Reinforcement} {Learning}: {KI}-{Agenten} mit {Python} und {PyTorch} programmieren}
      \field{year}{2020}
      \verb{file}
      \verb Zai and Brown - 2020 - Einstieg in Deep Reinforcement Learning KI-Agente.pdf:/home/tony/Zotero/storage/HXZRLXVX/Zai and Brown - 2020 - Einstieg in Deep Reinforcement Learning KI-Agente.pdf:application/pdf
      \endverb
    \endentry
    \entry{sutton_reinforcement_2014}{book}{}
      \name{author}{2}{}{%
        {{hash=eb920e5277d3d5fd0903f3cd41e11871}{%
           family={Sutton},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima S.},
           giveni={R\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=63f88d8d8cc347f8cc505512c809e269}{%
           family={Barto},
           familyi={B\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \list{location}{1}{%
        {Cambridge, Massachusetts}%
      }
      \list{publisher}{1}{%
        {The MIT Press}%
      }
      \strng{namehash}{3f6939b7bc162284c23cbb6fb6292c96}
      \strng{fullhash}{3f6939b7bc162284c23cbb6fb6292c96}
      \strng{bibnamehash}{3f6939b7bc162284c23cbb6fb6292c96}
      \strng{authorbibnamehash}{3f6939b7bc162284c23cbb6fb6292c96}
      \strng{authornamehash}{3f6939b7bc162284c23cbb6fb6292c96}
      \strng{authorfullhash}{3f6939b7bc162284c23cbb6fb6292c96}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{edition}{Nachdruck}
      \field{isbn}{978-0-262-19398-6}
      \field{series}{Adaptive computation and machine learning}
      \field{shorttitle}{Reinforcement learning}
      \field{title}{Reinforcement learning: an introduction}
      \field{year}{2014}
      \verb{file}
      \verb Sutton and Barto - 2014 - Reinforcement learning an introduction.pdf:/home/tony/Zotero/storage/I3L62CDK/Sutton and Barto - 2014 - Reinforcement learning an introduction.pdf:application/pdf
      \endverb
    \endentry
    \entry{schmidt_spiele_gmbh_spielregeln_nodate}{misc}{}
      \name{author}{1}{}{%
        {{hash=fa760eeedd155a2251e36e7066f0bd50}{%
           family={GmbH},
           familyi={G\bibinitperiod},
           given={Schmidt\bibnamedelima Spiele},
           giveni={S\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Schmidt Spiele GmbH}%
      }
      \strng{namehash}{fa760eeedd155a2251e36e7066f0bd50}
      \strng{fullhash}{fa760eeedd155a2251e36e7066f0bd50}
      \strng{bibnamehash}{fa760eeedd155a2251e36e7066f0bd50}
      \strng{authorbibnamehash}{fa760eeedd155a2251e36e7066f0bd50}
      \strng{authornamehash}{fa760eeedd155a2251e36e7066f0bd50}
      \strng{authorfullhash}{fa760eeedd155a2251e36e7066f0bd50}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{shorttitle}{Spielreglen '{Noch} mal!'}
      \field{title}{Spielregeln '{Noch} mal!'}
      \verb{file}
      \verb 49327_Noch_Mal_DE.pdf:/home/tony/Zotero/storage/P4DDMST7/49327_Noch_Mal_DE.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.schmidtspiele.de/files/Produkte/4/49327%20-%20Noch%20mal!/49327_Noch_Mal_DE.pdf
      \endverb
      \verb{url}
      \verb https://www.schmidtspiele.de/files/Produkte/4/49327%20-%20Noch%20mal!/49327_Noch_Mal_DE.pdf
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

